---
title: 'Goals Over Features for AI Coding Assistants'
description: 'Published December 15, 2025'
---

People often ask me: "What MCP servers should I install? What skills do I need?"

I get where they're coming from. Not everyone has time to optimize their setup,
and the feature landscape moves fast. But I think there's a more useful
question: **What goal are you trying to achieve?**

MCP servers, hooks, skills, and subagents are implementation details. They're
means to ends. If you start with implementation, you risk adding complexity
that doesn't serve you. If you start with goals, you often find simpler paths.

This post is in the context of Claude Code, but the same principles apply to
the Claude.ai web interface or any AI coding assistant.

---

## The Wrong Question

Here's a pattern I see:

| Implementation Question | Goal Question |
|------------------------|---------------|
| "Which MCP servers should I install?" | "What information does Claude lack that causes failures?" |
| "What hooks should I set up?" | "What checks do I do manually that could happen automatically?" |
| "Should I use the frontend design skill?" | "Is Claude defaulting to generic patterns instead of my project's?" |
| "How do I create a custom subagent?" | "What reasoning does my workflow need that the base model struggles with?" |

The implementation question assumes you need the feature. The goal question
helps you figure out if you do—and if a simpler solution exists.

{/* PLACEHOLDER: Add your concrete example here about the frontend design skill
    - what's actually valuable about it (forcing project-context-aware thinking)
    - how that could potentially be achieved other ways */}

## The Main Thesis

**Offload to software and filesystem, not to more instructions.**

Software executes deterministically. Files let you progressively disclose
information—Claude reads what it needs, when it needs it. Instructions in
`CLAUDE.md` compete for attention with your actual prompts.

When you find yourself writing elaborate instructions for Claude, ask: could
this be a script instead? A config file? A CLI that outputs structured data?

The goal is for Claude to deliver quality output with minimal oversight—like
working with a senior engineer. Senior engineers don't need exhaustive
instructions. They need good tools, clear context, and well-organized systems.

## A Framework: Five Goals

Rather than asking "what features should I use?", evaluate your setup against
these goals. Each can be improved with or without special features.

### 1. Self-Improvement

Is Claude getting better at what you ask it to do?

Models are static—they don't learn between sessions. Self-improvement is
fundamentally a context problem: how do you make lessons from past
conversations available to future ones?

**Questions to ask:**
- Do you review conversations for patterns? How do you capture them?
- Can Claude improve its own tooling? (CLIs, then Skills, then MCP—in order of
  simplicity)
- Can Claude reference relevant past work?

{/* PLACEHOLDER: Add your example of retrospectives or how you capture lessons
    from conversations */}

### 2. Parallelism

Can you run multiple Claude instances effectively?

For larger tasks, parallelism multiplies throughput. But it requires
coordination—Claude instances shouldn't step on each other.

**Approaches:**
- Git worktrees for isolated workspaces
- Tmux for managing multiple sessions
- Issue tracking to coordinate work across instances

{/* PLACEHOLDER: Add your example of parallel Claude workflows */}

### 3. Autonomy

Can Claude work independently without constant hand-holding?

Autonomy means Claude can make progress on complex tasks without waiting for
you at every decision point.

**Areas to consider:**
- Permission handling: what can Claude do without asking?
- Ambiguity: what should Claude do when requirements are unclear?
- Persistence: does Claude keep going, or give up at the first obstacle?

{/* PLACEHOLDER: Add your example of autonomy configuration */}

### 4. Correctness

Is Claude's output reliable?

You shouldn't have to review every line. Build systems that catch mistakes so
you can trust the output.

**Build software over time:**
- Robust test suites that Claude can run
- Pre-commit hooks for automatic validation
- CI pipelines that catch issues before merge

The more you invest in correctness infrastructure, the less you depend on
hoping Claude got it right.

{/* PLACEHOLDER: Add your example of correctness tooling */}

### 5. Efficiency

Is your setup token-efficient?

Context windows are large but not free. Noisy output wastes tokens. Verbose
configurations slow things down.

**Optimizations:**
- CLI tools that output clean, structured data (less noise to parse)
- "Claude Code Lite": disable unused tools, simplify context for focused tasks
- Progressive disclosure: don't load everything upfront

{/* PLACEHOLDER: Add your example of efficiency improvements */}

## Evaluating Features Against Goals

When a new feature ships, ask:

1. **Which goal does this serve?** If you can't map it to one of the five,
   you probably don't need it.

2. **What's the simplest implementation?** Maybe you need MCP. Maybe you need
   a 20-line bash script. Start simple.

3. **Does this reduce instructions or add them?** Prefer software that
   executes over prose that instructs.

The features aren't bad. MCP servers are powerful. Skills encode useful
patterns. Hooks automate real work. But they're tools, not goals. The
engineers who get the most from AI assistants are the ones who stay focused
on what they're trying to achieve—not what's new.
